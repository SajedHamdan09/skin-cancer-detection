{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting TDA features...\n",
      "TDA shape: (2000, 1300)\n",
      "Balancing with SMOTE...\n",
      "Final input shape: (9366, 1300)\n",
      "Epoch 1/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.3440 - loss: 2.0223 - precision: 0.4123 - recall: 0.2339 - val_accuracy: 0.5688 - val_loss: 1.1984 - val_precision: 0.7390 - val_recall: 0.3959\n",
      "Epoch 2/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.5231 - loss: 1.4153 - precision: 0.6043 - recall: 0.4092 - val_accuracy: 0.6734 - val_loss: 0.9578 - val_precision: 0.8102 - val_recall: 0.5171\n",
      "Epoch 3/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.5637 - loss: 1.2574 - precision: 0.6485 - recall: 0.4576 - val_accuracy: 0.7193 - val_loss: 0.8564 - val_precision: 0.8190 - val_recall: 0.5651\n",
      "Epoch 4/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6183 - loss: 1.1133 - precision: 0.6940 - recall: 0.5197 - val_accuracy: 0.7348 - val_loss: 0.7876 - val_precision: 0.8268 - val_recall: 0.6291\n",
      "Epoch 5/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6153 - loss: 1.0867 - precision: 0.6971 - recall: 0.5151 - val_accuracy: 0.7439 - val_loss: 0.7699 - val_precision: 0.8107 - val_recall: 0.6329\n",
      "Epoch 6/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6280 - loss: 1.0540 - precision: 0.6990 - recall: 0.5370 - val_accuracy: 0.7705 - val_loss: 0.6975 - val_precision: 0.8347 - val_recall: 0.6734\n",
      "Epoch 7/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6475 - loss: 1.0141 - precision: 0.7148 - recall: 0.5620 - val_accuracy: 0.7711 - val_loss: 0.6694 - val_precision: 0.8420 - val_recall: 0.6825\n",
      "Epoch 8/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6540 - loss: 0.9831 - precision: 0.7325 - recall: 0.5762 - val_accuracy: 0.7812 - val_loss: 0.6356 - val_precision: 0.8460 - val_recall: 0.6948\n",
      "Epoch 9/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6742 - loss: 0.9299 - precision: 0.7371 - recall: 0.5835 - val_accuracy: 0.7956 - val_loss: 0.6310 - val_precision: 0.8615 - val_recall: 0.7006\n",
      "Epoch 10/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6774 - loss: 0.9287 - precision: 0.7436 - recall: 0.5888 - val_accuracy: 0.7689 - val_loss: 0.6384 - val_precision: 0.8349 - val_recall: 0.6910\n",
      "Epoch 11/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6910 - loss: 0.8943 - precision: 0.7643 - recall: 0.6131 - val_accuracy: 0.8090 - val_loss: 0.5771 - val_precision: 0.8689 - val_recall: 0.7353\n",
      "Epoch 12/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7123 - loss: 0.8549 - precision: 0.7742 - recall: 0.6347 - val_accuracy: 0.8047 - val_loss: 0.5689 - val_precision: 0.8659 - val_recall: 0.7407\n",
      "Epoch 13/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7217 - loss: 0.7975 - precision: 0.7827 - recall: 0.6514 - val_accuracy: 0.8132 - val_loss: 0.5377 - val_precision: 0.8705 - val_recall: 0.7535\n",
      "Epoch 14/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7472 - loss: 0.7414 - precision: 0.8023 - recall: 0.6839 - val_accuracy: 0.8239 - val_loss: 0.5439 - val_precision: 0.8601 - val_recall: 0.7641\n",
      "Epoch 15/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7540 - loss: 0.7098 - precision: 0.8096 - recall: 0.6923 - val_accuracy: 0.8388 - val_loss: 0.4771 - val_precision: 0.8837 - val_recall: 0.7828\n",
      "Epoch 16/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7454 - loss: 0.7309 - precision: 0.8060 - recall: 0.6830 - val_accuracy: 0.8388 - val_loss: 0.5018 - val_precision: 0.8830 - val_recall: 0.7775\n",
      "Epoch 17/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7512 - loss: 0.7024 - precision: 0.8175 - recall: 0.6917 - val_accuracy: 0.8410 - val_loss: 0.4775 - val_precision: 0.8851 - val_recall: 0.7850\n",
      "Epoch 18/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7498 - loss: 0.7035 - precision: 0.8068 - recall: 0.6879 - val_accuracy: 0.8367 - val_loss: 0.4878 - val_precision: 0.8805 - val_recall: 0.7903\n",
      "Epoch 19/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7666 - loss: 0.6680 - precision: 0.8116 - recall: 0.7173 - val_accuracy: 0.8442 - val_loss: 0.4539 - val_precision: 0.8818 - val_recall: 0.8004\n",
      "Epoch 20/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7686 - loss: 0.6574 - precision: 0.8182 - recall: 0.7104 - val_accuracy: 0.8559 - val_loss: 0.4523 - val_precision: 0.8906 - val_recall: 0.8122\n",
      "Epoch 21/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7634 - loss: 0.6631 - precision: 0.8180 - recall: 0.7067 - val_accuracy: 0.8565 - val_loss: 0.4340 - val_precision: 0.8939 - val_recall: 0.8138\n",
      "Epoch 22/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7594 - loss: 0.6761 - precision: 0.8082 - recall: 0.7060 - val_accuracy: 0.8607 - val_loss: 0.4249 - val_precision: 0.9015 - val_recall: 0.8202\n",
      "Epoch 23/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7688 - loss: 0.6544 - precision: 0.8162 - recall: 0.7197 - val_accuracy: 0.8655 - val_loss: 0.4250 - val_precision: 0.9031 - val_recall: 0.8207\n",
      "Epoch 24/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7747 - loss: 0.6449 - precision: 0.8244 - recall: 0.7199 - val_accuracy: 0.8581 - val_loss: 0.4130 - val_precision: 0.8860 - val_recall: 0.8212\n",
      "Epoch 25/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7810 - loss: 0.6056 - precision: 0.8298 - recall: 0.7334 - val_accuracy: 0.8661 - val_loss: 0.3953 - val_precision: 0.8963 - val_recall: 0.8346\n",
      "Epoch 26/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7950 - loss: 0.6071 - precision: 0.8377 - recall: 0.7451 - val_accuracy: 0.8746 - val_loss: 0.3854 - val_precision: 0.9054 - val_recall: 0.8324\n",
      "Epoch 27/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7828 - loss: 0.5997 - precision: 0.8298 - recall: 0.7345 - val_accuracy: 0.8757 - val_loss: 0.3897 - val_precision: 0.9053 - val_recall: 0.8314\n",
      "Epoch 28/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7988 - loss: 0.5718 - precision: 0.8405 - recall: 0.7520 - val_accuracy: 0.8730 - val_loss: 0.3787 - val_precision: 0.9083 - val_recall: 0.8404\n",
      "Epoch 29/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7927 - loss: 0.5901 - precision: 0.8428 - recall: 0.7454 - val_accuracy: 0.8725 - val_loss: 0.3831 - val_precision: 0.9030 - val_recall: 0.8394\n",
      "Epoch 30/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7933 - loss: 0.5818 - precision: 0.8314 - recall: 0.7520 - val_accuracy: 0.8714 - val_loss: 0.3762 - val_precision: 0.9060 - val_recall: 0.8436\n",
      "Epoch 31/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8096 - loss: 0.5538 - precision: 0.8515 - recall: 0.7623 - val_accuracy: 0.8783 - val_loss: 0.3610 - val_precision: 0.9098 - val_recall: 0.8501\n",
      "Epoch 32/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8217 - loss: 0.5243 - precision: 0.8568 - recall: 0.7736 - val_accuracy: 0.8837 - val_loss: 0.3568 - val_precision: 0.9086 - val_recall: 0.8490\n",
      "Epoch 33/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8006 - loss: 0.5580 - precision: 0.8417 - recall: 0.7534 - val_accuracy: 0.8831 - val_loss: 0.3724 - val_precision: 0.9102 - val_recall: 0.8490\n",
      "Epoch 34/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8087 - loss: 0.5500 - precision: 0.8438 - recall: 0.7618 - val_accuracy: 0.8922 - val_loss: 0.3356 - val_precision: 0.9137 - val_recall: 0.8591\n",
      "Epoch 35/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8161 - loss: 0.5125 - precision: 0.8538 - recall: 0.7781 - val_accuracy: 0.8847 - val_loss: 0.3298 - val_precision: 0.9189 - val_recall: 0.8581\n",
      "Epoch 36/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8415 - loss: 0.4581 - precision: 0.8738 - recall: 0.8008 - val_accuracy: 0.8874 - val_loss: 0.3272 - val_precision: 0.9157 - val_recall: 0.8581\n",
      "Epoch 37/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8200 - loss: 0.5197 - precision: 0.8537 - recall: 0.7836 - val_accuracy: 0.8927 - val_loss: 0.3258 - val_precision: 0.9192 - val_recall: 0.8677\n",
      "Epoch 38/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8013 - loss: 0.5587 - precision: 0.8416 - recall: 0.7498 - val_accuracy: 0.8890 - val_loss: 0.3411 - val_precision: 0.9201 - val_recall: 0.8602\n",
      "Epoch 39/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8121 - loss: 0.5304 - precision: 0.8540 - recall: 0.7622 - val_accuracy: 0.8735 - val_loss: 0.3569 - val_precision: 0.9040 - val_recall: 0.8490\n",
      "Epoch 40/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8154 - loss: 0.5165 - precision: 0.8528 - recall: 0.7776 - val_accuracy: 0.8885 - val_loss: 0.3278 - val_precision: 0.9137 - val_recall: 0.8645\n",
      "Epoch 41/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8329 - loss: 0.4798 - precision: 0.8686 - recall: 0.7971 - val_accuracy: 0.8794 - val_loss: 0.3279 - val_precision: 0.9079 - val_recall: 0.8623\n",
      "Epoch 42/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8361 - loss: 0.4720 - precision: 0.8707 - recall: 0.8031 - val_accuracy: 0.8906 - val_loss: 0.2960 - val_precision: 0.9172 - val_recall: 0.8687\n",
      "Epoch 43/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8345 - loss: 0.4798 - precision: 0.8644 - recall: 0.7998 - val_accuracy: 0.8949 - val_loss: 0.3071 - val_precision: 0.9190 - val_recall: 0.8778\n",
      "Epoch 44/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8339 - loss: 0.4668 - precision: 0.8664 - recall: 0.7969 - val_accuracy: 0.8959 - val_loss: 0.3071 - val_precision: 0.9215 - val_recall: 0.8767\n",
      "Epoch 45/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8391 - loss: 0.4666 - precision: 0.8697 - recall: 0.7978 - val_accuracy: 0.8943 - val_loss: 0.3064 - val_precision: 0.9194 - val_recall: 0.8767\n",
      "Epoch 46/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8471 - loss: 0.4396 - precision: 0.8779 - recall: 0.8139 - val_accuracy: 0.9136 - val_loss: 0.2758 - val_precision: 0.9323 - val_recall: 0.8885\n",
      "Epoch 47/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8514 - loss: 0.4282 - precision: 0.8792 - recall: 0.8166 - val_accuracy: 0.9082 - val_loss: 0.2724 - val_precision: 0.9291 - val_recall: 0.8949\n",
      "Epoch 48/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8384 - loss: 0.4484 - precision: 0.8683 - recall: 0.8040 - val_accuracy: 0.9023 - val_loss: 0.2822 - val_precision: 0.9193 - val_recall: 0.8815\n",
      "Epoch 49/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8486 - loss: 0.4198 - precision: 0.8790 - recall: 0.8240 - val_accuracy: 0.9098 - val_loss: 0.2750 - val_precision: 0.9283 - val_recall: 0.8911\n",
      "Epoch 50/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8458 - loss: 0.4435 - precision: 0.8791 - recall: 0.8122 - val_accuracy: 0.9109 - val_loss: 0.2838 - val_precision: 0.9319 - val_recall: 0.8837\n",
      "Epoch 51/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8476 - loss: 0.4251 - precision: 0.8768 - recall: 0.8148 - val_accuracy: 0.9088 - val_loss: 0.2841 - val_precision: 0.9287 - val_recall: 0.8901\n",
      "Epoch 52/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8540 - loss: 0.4200 - precision: 0.8817 - recall: 0.8236 - val_accuracy: 0.9093 - val_loss: 0.2673 - val_precision: 0.9265 - val_recall: 0.8943\n",
      "Epoch 53/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8638 - loss: 0.3867 - precision: 0.8947 - recall: 0.8358 - val_accuracy: 0.9200 - val_loss: 0.2597 - val_precision: 0.9330 - val_recall: 0.8991\n",
      "Epoch 54/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8560 - loss: 0.4197 - precision: 0.8816 - recall: 0.8222 - val_accuracy: 0.9114 - val_loss: 0.3067 - val_precision: 0.9251 - val_recall: 0.8901\n",
      "Epoch 55/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8487 - loss: 0.4211 - precision: 0.8753 - recall: 0.8160 - val_accuracy: 0.9072 - val_loss: 0.2688 - val_precision: 0.9262 - val_recall: 0.8906\n",
      "Epoch 56/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8488 - loss: 0.4293 - precision: 0.8760 - recall: 0.8205 - val_accuracy: 0.9130 - val_loss: 0.2683 - val_precision: 0.9311 - val_recall: 0.8943\n",
      "Epoch 57/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8530 - loss: 0.4044 - precision: 0.8806 - recall: 0.8264 - val_accuracy: 0.9168 - val_loss: 0.2572 - val_precision: 0.9325 - val_recall: 0.8997\n",
      "Epoch 58/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8595 - loss: 0.3942 - precision: 0.8839 - recall: 0.8329 - val_accuracy: 0.9178 - val_loss: 0.2596 - val_precision: 0.9373 - val_recall: 0.9013\n",
      "Epoch 59/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8557 - loss: 0.3992 - precision: 0.8838 - recall: 0.8285 - val_accuracy: 0.9168 - val_loss: 0.2573 - val_precision: 0.9303 - val_recall: 0.8981\n",
      "Epoch 60/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8623 - loss: 0.4063 - precision: 0.8904 - recall: 0.8285 - val_accuracy: 0.9162 - val_loss: 0.2640 - val_precision: 0.9297 - val_recall: 0.8965\n",
      "Epoch 61/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8581 - loss: 0.3987 - precision: 0.8819 - recall: 0.8275 - val_accuracy: 0.9253 - val_loss: 0.2488 - val_precision: 0.9333 - val_recall: 0.9109\n",
      "Epoch 62/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8535 - loss: 0.4053 - precision: 0.8771 - recall: 0.8234 - val_accuracy: 0.9184 - val_loss: 0.2597 - val_precision: 0.9346 - val_recall: 0.8997\n",
      "Epoch 63/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8553 - loss: 0.4070 - precision: 0.8836 - recall: 0.8271 - val_accuracy: 0.9221 - val_loss: 0.2547 - val_precision: 0.9379 - val_recall: 0.9029\n",
      "Epoch 64/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8564 - loss: 0.3983 - precision: 0.8825 - recall: 0.8296 - val_accuracy: 0.9189 - val_loss: 0.2429 - val_precision: 0.9355 - val_recall: 0.9055\n",
      "Epoch 65/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8655 - loss: 0.3841 - precision: 0.8894 - recall: 0.8415 - val_accuracy: 0.9194 - val_loss: 0.2584 - val_precision: 0.9297 - val_recall: 0.9029\n",
      "Epoch 66/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8759 - loss: 0.3609 - precision: 0.8977 - recall: 0.8510 - val_accuracy: 0.9285 - val_loss: 0.2324 - val_precision: 0.9430 - val_recall: 0.9098\n",
      "Epoch 67/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8702 - loss: 0.3631 - precision: 0.8948 - recall: 0.8458 - val_accuracy: 0.9248 - val_loss: 0.2471 - val_precision: 0.9358 - val_recall: 0.9098\n",
      "Epoch 68/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8594 - loss: 0.3884 - precision: 0.8823 - recall: 0.8342 - val_accuracy: 0.9264 - val_loss: 0.2375 - val_precision: 0.9385 - val_recall: 0.9120\n",
      "Epoch 69/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8770 - loss: 0.3453 - precision: 0.9041 - recall: 0.8544 - val_accuracy: 0.9237 - val_loss: 0.2406 - val_precision: 0.9389 - val_recall: 0.9098\n",
      "Epoch 70/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8772 - loss: 0.3528 - precision: 0.8945 - recall: 0.8531 - val_accuracy: 0.9141 - val_loss: 0.2569 - val_precision: 0.9300 - val_recall: 0.8933\n",
      "Epoch 71/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8668 - loss: 0.3839 - precision: 0.8939 - recall: 0.8442 - val_accuracy: 0.9248 - val_loss: 0.2401 - val_precision: 0.9385 - val_recall: 0.9125\n",
      "Epoch 72/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8706 - loss: 0.3731 - precision: 0.8899 - recall: 0.8486 - val_accuracy: 0.9242 - val_loss: 0.2294 - val_precision: 0.9407 - val_recall: 0.9136\n",
      "Epoch 73/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8703 - loss: 0.3836 - precision: 0.8981 - recall: 0.8397 - val_accuracy: 0.9285 - val_loss: 0.2261 - val_precision: 0.9422 - val_recall: 0.9141\n",
      "Epoch 74/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8693 - loss: 0.3815 - precision: 0.8941 - recall: 0.8416 - val_accuracy: 0.9168 - val_loss: 0.2521 - val_precision: 0.9287 - val_recall: 0.9039\n",
      "Epoch 75/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8893 - loss: 0.3207 - precision: 0.9104 - recall: 0.8696 - val_accuracy: 0.9285 - val_loss: 0.2175 - val_precision: 0.9388 - val_recall: 0.9168\n",
      "Epoch 76/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8934 - loss: 0.3060 - precision: 0.9148 - recall: 0.8756 - val_accuracy: 0.9269 - val_loss: 0.2277 - val_precision: 0.9349 - val_recall: 0.9189\n",
      "Epoch 77/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8913 - loss: 0.3100 - precision: 0.9082 - recall: 0.8702 - val_accuracy: 0.9360 - val_loss: 0.2039 - val_precision: 0.9475 - val_recall: 0.9242\n",
      "Epoch 78/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8927 - loss: 0.3087 - precision: 0.9129 - recall: 0.8705 - val_accuracy: 0.9328 - val_loss: 0.2063 - val_precision: 0.9435 - val_recall: 0.9178\n",
      "Epoch 79/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9007 - loss: 0.2925 - precision: 0.9171 - recall: 0.8796 - val_accuracy: 0.9365 - val_loss: 0.2107 - val_precision: 0.9479 - val_recall: 0.9232\n",
      "Epoch 80/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8978 - loss: 0.2862 - precision: 0.9158 - recall: 0.8822 - val_accuracy: 0.9370 - val_loss: 0.1980 - val_precision: 0.9444 - val_recall: 0.9248\n",
      "Epoch 81/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.9017 - loss: 0.2975 - precision: 0.9188 - recall: 0.8825 - val_accuracy: 0.9360 - val_loss: 0.2061 - val_precision: 0.9477 - val_recall: 0.9274\n",
      "Epoch 82/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8848 - loss: 0.3227 - precision: 0.9065 - recall: 0.8626 - val_accuracy: 0.9328 - val_loss: 0.2242 - val_precision: 0.9391 - val_recall: 0.9216\n",
      "Epoch 83/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8836 - loss: 0.3201 - precision: 0.9024 - recall: 0.8672 - val_accuracy: 0.9317 - val_loss: 0.2160 - val_precision: 0.9418 - val_recall: 0.9248\n",
      "Epoch 84/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8846 - loss: 0.3192 - precision: 0.9030 - recall: 0.8685 - val_accuracy: 0.9365 - val_loss: 0.2045 - val_precision: 0.9495 - val_recall: 0.9237\n",
      "Epoch 85/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8885 - loss: 0.3219 - precision: 0.9076 - recall: 0.8667 - val_accuracy: 0.9408 - val_loss: 0.1939 - val_precision: 0.9505 - val_recall: 0.9322\n",
      "Epoch 86/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9023 - loss: 0.2872 - precision: 0.9198 - recall: 0.8862 - val_accuracy: 0.9424 - val_loss: 0.1859 - val_precision: 0.9532 - val_recall: 0.9338\n",
      "Epoch 87/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8864 - loss: 0.3190 - precision: 0.9068 - recall: 0.8725 - val_accuracy: 0.9317 - val_loss: 0.2120 - val_precision: 0.9439 - val_recall: 0.9253\n",
      "Epoch 88/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8909 - loss: 0.3058 - precision: 0.9111 - recall: 0.8736 - val_accuracy: 0.9296 - val_loss: 0.2317 - val_precision: 0.9422 - val_recall: 0.9136\n",
      "Epoch 89/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8895 - loss: 0.3261 - precision: 0.9099 - recall: 0.8692 - val_accuracy: 0.9338 - val_loss: 0.2033 - val_precision: 0.9439 - val_recall: 0.9242\n",
      "Epoch 90/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8956 - loss: 0.2898 - precision: 0.9127 - recall: 0.8788 - val_accuracy: 0.9392 - val_loss: 0.1950 - val_precision: 0.9499 - val_recall: 0.9312\n",
      "Epoch 91/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9071 - loss: 0.2750 - precision: 0.9259 - recall: 0.8914 - val_accuracy: 0.9376 - val_loss: 0.1928 - val_precision: 0.9459 - val_recall: 0.9328\n",
      "Epoch 92/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9007 - loss: 0.2849 - precision: 0.9164 - recall: 0.8816 - val_accuracy: 0.9338 - val_loss: 0.2031 - val_precision: 0.9436 - val_recall: 0.9280\n",
      "Epoch 93/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.9074 - loss: 0.2689 - precision: 0.9229 - recall: 0.8886 - val_accuracy: 0.9434 - val_loss: 0.1931 - val_precision: 0.9537 - val_recall: 0.9349\n",
      "Epoch 94/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8914 - loss: 0.3145 - precision: 0.9099 - recall: 0.8739 - val_accuracy: 0.9386 - val_loss: 0.2037 - val_precision: 0.9504 - val_recall: 0.9301\n",
      "Epoch 95/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8939 - loss: 0.3092 - precision: 0.9133 - recall: 0.8741 - val_accuracy: 0.9408 - val_loss: 0.1879 - val_precision: 0.9492 - val_recall: 0.9280\n",
      "Epoch 96/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8864 - loss: 0.3265 - precision: 0.9029 - recall: 0.8704 - val_accuracy: 0.9418 - val_loss: 0.1901 - val_precision: 0.9479 - val_recall: 0.9317\n",
      "Epoch 97/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8961 - loss: 0.3048 - precision: 0.9146 - recall: 0.8813 - val_accuracy: 0.9376 - val_loss: 0.1930 - val_precision: 0.9461 - val_recall: 0.9274\n",
      "Epoch 98/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8749 - loss: 0.3507 - precision: 0.8938 - recall: 0.8522 - val_accuracy: 0.9290 - val_loss: 0.2170 - val_precision: 0.9407 - val_recall: 0.9226\n",
      "Epoch 99/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8825 - loss: 0.3334 - precision: 0.9004 - recall: 0.8643 - val_accuracy: 0.9290 - val_loss: 0.2087 - val_precision: 0.9430 - val_recall: 0.9184\n",
      "Epoch 100/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8983 - loss: 0.2922 - precision: 0.9169 - recall: 0.8814 - val_accuracy: 0.9424 - val_loss: 0.1734 - val_precision: 0.9538 - val_recall: 0.9370\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9496 - loss: 0.1656 - precision: 0.9601 - recall: 0.9454\n",
      "Test - Accuracy: 0.9424 | Precision: 0.9538 | Recall: 0.9370\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "\n",
    "from gtda.homology import CubicalPersistence\n",
    "from gtda.diagrams import PersistenceImage, PersistenceLandscape\n",
    "\n",
    "X_img = np.load(\"/home/sajedhamdan/Desktop/skin_cancer/images_train_256x192.npy\") \n",
    "y = np.load(\"/home/sajedhamdan/Desktop/skin_cancer/train_labels.npy\")            \n",
    "X_img = X_img.astype(np.float32)\n",
    "y_cat = to_categorical(y)\n",
    "\n",
    "sample_size = 2000\n",
    "X_img, _, y, _ = train_test_split(\n",
    "    X_img, y, train_size=sample_size, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# TDA Feature Extraction\n",
    "def extract_tda_features(X_rgb):\n",
    "    X_gray = 0.2989 * X_rgb[..., 0] + 0.5870 * X_rgb[..., 1] + 0.1140 * X_rgb[..., 2]\n",
    "    cp = CubicalPersistence(homology_dimensions=[0, 1], n_jobs=-1)\n",
    "    diagrams = cp.fit_transform(X_gray)\n",
    "\n",
    "    pi = PersistenceImage(sigma=1.0, n_bins=20, weight_function=lambda x: x[1] ** 2)\n",
    "    pi_feat = pi.fit_transform(diagrams).reshape(len(diagrams), -1)\n",
    "\n",
    "    pl = PersistenceLandscape(n_layers=5, n_bins=50)\n",
    "    pl_feat = pl.fit_transform(diagrams).reshape(len(diagrams), -1)\n",
    "\n",
    "    return np.hstack((pi_feat, pl_feat))\n",
    "\n",
    "print(\"Extracting TDA features...\")\n",
    "X_tda_features = extract_tda_features(X_img)\n",
    "print(\"TDA shape:\", X_tda_features.shape)\n",
    "\n",
    "print(\"Balancing with SMOTE...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_balanced, y_bal = smote.fit_resample(X_tda_features, y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_final = scaler.fit_transform(X_balanced)\n",
    "y_bal_cat = to_categorical(y_bal)\n",
    "\n",
    "\n",
    "y_bal_int = np.argmax(y_bal_cat, axis=1)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_bal_int), y=y_bal_int)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "\n",
    "print(\"Final input shape:\", X_final.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_final, y_bal_cat, test_size=0.2, random_state=42, stratify=y_bal)\n",
    "\n",
    "\n",
    "input_layer = Input(shape=(X_final.shape[1],))\n",
    "x = Dense(512, activation='relu')(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output_layer = Dense(7, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test, y_test),\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "results = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test - Accuracy: {results[1]:.4f} | Precision: {results[2]:.4f} | Recall: {results[3]:.4f}\")\n",
    "\n",
    "model.save(\"tda_resnet_model_v2.keras\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
