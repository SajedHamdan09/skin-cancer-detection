{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 13:26:03.896318: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-08 13:26:04.068280: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749378364.133675   30786 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749378364.152590   30786 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749378364.284177   30786 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749378364.284201   30786 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749378364.284202   30786 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749378364.284203   30786 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-08 13:26:04.298950: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting TDA features...\n",
      "TDA features shape: (2000, 1300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 13:29:34.244584: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting CNN features...\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step\n",
      "CNN features shape: (2000, 2048)\n",
      "Balancing with SMOTE...\n",
      "Final input shape: (9366, 3348)\n",
      "Epoch 1/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.3122 - loss: 1.8456 - precision: 0.4081 - recall: 0.1227 - val_accuracy: 0.5672 - val_loss: 1.1661 - val_precision: 0.7475 - val_recall: 0.3207 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.5036 - loss: 1.3149 - precision: 0.6414 - recall: 0.2840 - val_accuracy: 0.6318 - val_loss: 1.0133 - val_precision: 0.8187 - val_recall: 0.4216 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.5815 - loss: 1.1522 - precision: 0.7186 - recall: 0.3760 - val_accuracy: 0.6601 - val_loss: 0.9111 - val_precision: 0.8224 - val_recall: 0.4968 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.6136 - loss: 1.0502 - precision: 0.7536 - recall: 0.4418 - val_accuracy: 0.7076 - val_loss: 0.8251 - val_precision: 0.8420 - val_recall: 0.5603 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.6430 - loss: 0.9830 - precision: 0.7640 - recall: 0.4751 - val_accuracy: 0.7081 - val_loss: 0.7857 - val_precision: 0.8176 - val_recall: 0.5763 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.6582 - loss: 0.9266 - precision: 0.7775 - recall: 0.5154 - val_accuracy: 0.7444 - val_loss: 0.7163 - val_precision: 0.8392 - val_recall: 0.6185 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.6840 - loss: 0.8699 - precision: 0.7856 - recall: 0.5543 - val_accuracy: 0.7540 - val_loss: 0.6794 - val_precision: 0.8486 - val_recall: 0.6521 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.7038 - loss: 0.8222 - precision: 0.7976 - recall: 0.5780 - val_accuracy: 0.7801 - val_loss: 0.6301 - val_precision: 0.8592 - val_recall: 0.6772 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.7337 - loss: 0.7698 - precision: 0.8087 - recall: 0.6184 - val_accuracy: 0.7834 - val_loss: 0.6108 - val_precision: 0.8636 - val_recall: 0.6825 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.7430 - loss: 0.7337 - precision: 0.8151 - recall: 0.6302 - val_accuracy: 0.8052 - val_loss: 0.5617 - val_precision: 0.8756 - val_recall: 0.7172 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.7535 - loss: 0.6905 - precision: 0.8302 - recall: 0.6616 - val_accuracy: 0.7956 - val_loss: 0.5655 - val_precision: 0.8632 - val_recall: 0.7241 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.7656 - loss: 0.6625 - precision: 0.8362 - recall: 0.6703 - val_accuracy: 0.8111 - val_loss: 0.5260 - val_precision: 0.8779 - val_recall: 0.7407 - learning_rate: 1.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.7801 - loss: 0.6240 - precision: 0.8487 - recall: 0.6974 - val_accuracy: 0.8084 - val_loss: 0.5191 - val_precision: 0.8670 - val_recall: 0.7481 - learning_rate: 1.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.7972 - loss: 0.6064 - precision: 0.8501 - recall: 0.7172 - val_accuracy: 0.8314 - val_loss: 0.4885 - val_precision: 0.8880 - val_recall: 0.7700 - learning_rate: 1.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.7789 - loss: 0.6265 - precision: 0.8415 - recall: 0.7028 - val_accuracy: 0.8191 - val_loss: 0.5049 - val_precision: 0.8665 - val_recall: 0.7652 - learning_rate: 1.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.7881 - loss: 0.5993 - precision: 0.8485 - recall: 0.7214 - val_accuracy: 0.8383 - val_loss: 0.4542 - val_precision: 0.8805 - val_recall: 0.7823 - learning_rate: 1.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8014 - loss: 0.5707 - precision: 0.8566 - recall: 0.7307 - val_accuracy: 0.8511 - val_loss: 0.4269 - val_precision: 0.8969 - val_recall: 0.7983 - learning_rate: 1.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8142 - loss: 0.5343 - precision: 0.8691 - recall: 0.7503 - val_accuracy: 0.8527 - val_loss: 0.4122 - val_precision: 0.8989 - val_recall: 0.8111 - learning_rate: 1.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8120 - loss: 0.5560 - precision: 0.8638 - recall: 0.7482 - val_accuracy: 0.8549 - val_loss: 0.4041 - val_precision: 0.8945 - val_recall: 0.8058 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8278 - loss: 0.5011 - precision: 0.8740 - recall: 0.7690 - val_accuracy: 0.8522 - val_loss: 0.4032 - val_precision: 0.8881 - val_recall: 0.8047 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.8253 - loss: 0.4894 - precision: 0.8720 - recall: 0.7732 - val_accuracy: 0.8746 - val_loss: 0.3738 - val_precision: 0.9091 - val_recall: 0.8223 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.8350 - loss: 0.4679 - precision: 0.8810 - recall: 0.7831 - val_accuracy: 0.8693 - val_loss: 0.3627 - val_precision: 0.8993 - val_recall: 0.8340 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8514 - loss: 0.4505 - precision: 0.8872 - recall: 0.8041 - val_accuracy: 0.8671 - val_loss: 0.3685 - val_precision: 0.8989 - val_recall: 0.8351 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.8524 - loss: 0.4357 - precision: 0.8903 - recall: 0.8015 - val_accuracy: 0.8767 - val_loss: 0.3623 - val_precision: 0.9033 - val_recall: 0.8372 - learning_rate: 1.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.8561 - loss: 0.4147 - precision: 0.8914 - recall: 0.8119 - val_accuracy: 0.8863 - val_loss: 0.3330 - val_precision: 0.9096 - val_recall: 0.8485 - learning_rate: 1.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8652 - loss: 0.4103 - precision: 0.8961 - recall: 0.8256 - val_accuracy: 0.8783 - val_loss: 0.3457 - val_precision: 0.9047 - val_recall: 0.8410 - learning_rate: 1.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.8603 - loss: 0.4176 - precision: 0.8949 - recall: 0.8211 - val_accuracy: 0.8837 - val_loss: 0.3359 - val_precision: 0.9113 - val_recall: 0.8549 - learning_rate: 1.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8657 - loss: 0.3937 - precision: 0.8990 - recall: 0.8238 - val_accuracy: 0.8815 - val_loss: 0.3310 - val_precision: 0.9106 - val_recall: 0.8479 - learning_rate: 1.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8719 - loss: 0.3736 - precision: 0.9002 - recall: 0.8333 - val_accuracy: 0.8831 - val_loss: 0.3298 - val_precision: 0.9077 - val_recall: 0.8506 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8771 - loss: 0.3713 - precision: 0.9058 - recall: 0.8410 - val_accuracy: 0.8847 - val_loss: 0.3160 - val_precision: 0.9121 - val_recall: 0.8581 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8859 - loss: 0.3508 - precision: 0.9140 - recall: 0.8494 - val_accuracy: 0.9018 - val_loss: 0.2880 - val_precision: 0.9239 - val_recall: 0.8746 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8760 - loss: 0.3671 - precision: 0.9020 - recall: 0.8418 - val_accuracy: 0.8965 - val_loss: 0.2880 - val_precision: 0.9175 - val_recall: 0.8725 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.8788 - loss: 0.3619 - precision: 0.9066 - recall: 0.8472 - val_accuracy: 0.8986 - val_loss: 0.2800 - val_precision: 0.9184 - val_recall: 0.8767 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8884 - loss: 0.3264 - precision: 0.9155 - recall: 0.8603 - val_accuracy: 0.8927 - val_loss: 0.2863 - val_precision: 0.9166 - val_recall: 0.8682 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8923 - loss: 0.3281 - precision: 0.9127 - recall: 0.8602 - val_accuracy: 0.8975 - val_loss: 0.2795 - val_precision: 0.9155 - val_recall: 0.8730 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8970 - loss: 0.3203 - precision: 0.9165 - recall: 0.8668 - val_accuracy: 0.9114 - val_loss: 0.2557 - val_precision: 0.9273 - val_recall: 0.8917 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.8971 - loss: 0.3117 - precision: 0.9157 - recall: 0.8676 - val_accuracy: 0.9109 - val_loss: 0.2572 - val_precision: 0.9287 - val_recall: 0.8901 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9020 - loss: 0.3099 - precision: 0.9201 - recall: 0.8730 - val_accuracy: 0.9141 - val_loss: 0.2612 - val_precision: 0.9265 - val_recall: 0.8949 - learning_rate: 1.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9014 - loss: 0.2925 - precision: 0.9228 - recall: 0.8799 - val_accuracy: 0.9109 - val_loss: 0.2530 - val_precision: 0.9294 - val_recall: 0.8922 - learning_rate: 1.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.8957 - loss: 0.3100 - precision: 0.9177 - recall: 0.8690 - val_accuracy: 0.9216 - val_loss: 0.2379 - val_precision: 0.9320 - val_recall: 0.8997 - learning_rate: 1.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8971 - loss: 0.2968 - precision: 0.9181 - recall: 0.8735 - val_accuracy: 0.9072 - val_loss: 0.2651 - val_precision: 0.9238 - val_recall: 0.8863 - learning_rate: 1.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9029 - loss: 0.2882 - precision: 0.9205 - recall: 0.8796 - val_accuracy: 0.9296 - val_loss: 0.2306 - val_precision: 0.9406 - val_recall: 0.9125 - learning_rate: 1.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9083 - loss: 0.2795 - precision: 0.9265 - recall: 0.8881 - val_accuracy: 0.9226 - val_loss: 0.2416 - val_precision: 0.9369 - val_recall: 0.9034 - learning_rate: 1.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9108 - loss: 0.2631 - precision: 0.9311 - recall: 0.8918 - val_accuracy: 0.9258 - val_loss: 0.2292 - val_precision: 0.9347 - val_recall: 0.9082 - learning_rate: 1.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9085 - loss: 0.2715 - precision: 0.9256 - recall: 0.8842 - val_accuracy: 0.9232 - val_loss: 0.2249 - val_precision: 0.9378 - val_recall: 0.9093 - learning_rate: 1.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9205 - loss: 0.2504 - precision: 0.9393 - recall: 0.9009 - val_accuracy: 0.9168 - val_loss: 0.2412 - val_precision: 0.9295 - val_recall: 0.9002 - learning_rate: 1.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9126 - loss: 0.2605 - precision: 0.9262 - recall: 0.8962 - val_accuracy: 0.9274 - val_loss: 0.2107 - val_precision: 0.9355 - val_recall: 0.9136 - learning_rate: 1.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9222 - loss: 0.2398 - precision: 0.9363 - recall: 0.9041 - val_accuracy: 0.9344 - val_loss: 0.1994 - val_precision: 0.9407 - val_recall: 0.9221 - learning_rate: 1.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9173 - loss: 0.2386 - precision: 0.9363 - recall: 0.8986 - val_accuracy: 0.9226 - val_loss: 0.2293 - val_precision: 0.9301 - val_recall: 0.9023 - learning_rate: 1.0000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9227 - loss: 0.2398 - precision: 0.9359 - recall: 0.9058 - val_accuracy: 0.9258 - val_loss: 0.2115 - val_precision: 0.9390 - val_recall: 0.9120 - learning_rate: 1.0000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9171 - loss: 0.2591 - precision: 0.9314 - recall: 0.9017 - val_accuracy: 0.9216 - val_loss: 0.2114 - val_precision: 0.9350 - val_recall: 0.9136 - learning_rate: 1.0000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9139 - loss: 0.2611 - precision: 0.9278 - recall: 0.8973 - val_accuracy: 0.9296 - val_loss: 0.2076 - val_precision: 0.9411 - val_recall: 0.9210 - learning_rate: 1.0000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m116/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9186 - loss: 0.2502 - precision: 0.9329 - recall: 0.8985\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9187 - loss: 0.2499 - precision: 0.9330 - recall: 0.8987 - val_accuracy: 0.9344 - val_loss: 0.2027 - val_precision: 0.9430 - val_recall: 0.9178 - learning_rate: 1.0000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9348 - loss: 0.1991 - precision: 0.9479 - recall: 0.9199 - val_accuracy: 0.9370 - val_loss: 0.1893 - val_precision: 0.9440 - val_recall: 0.9264 - learning_rate: 5.0000e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9357 - loss: 0.1968 - precision: 0.9483 - recall: 0.9253 - val_accuracy: 0.9424 - val_loss: 0.1791 - val_precision: 0.9486 - val_recall: 0.9354 - learning_rate: 5.0000e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9235 - loss: 0.2259 - precision: 0.9369 - recall: 0.9128 - val_accuracy: 0.9408 - val_loss: 0.1885 - val_precision: 0.9478 - val_recall: 0.9296 - learning_rate: 5.0000e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9456 - loss: 0.1727 - precision: 0.9568 - recall: 0.9346 - val_accuracy: 0.9402 - val_loss: 0.1818 - val_precision: 0.9474 - val_recall: 0.9317 - learning_rate: 5.0000e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9430 - loss: 0.1809 - precision: 0.9530 - recall: 0.9298 - val_accuracy: 0.9418 - val_loss: 0.1784 - val_precision: 0.9499 - val_recall: 0.9306 - learning_rate: 5.0000e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9490 - loss: 0.1655 - precision: 0.9577 - recall: 0.9384 - val_accuracy: 0.9381 - val_loss: 0.1829 - val_precision: 0.9451 - val_recall: 0.9274 - learning_rate: 5.0000e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9449 - loss: 0.1689 - precision: 0.9563 - recall: 0.9356 - val_accuracy: 0.9424 - val_loss: 0.1750 - val_precision: 0.9475 - val_recall: 0.9344 - learning_rate: 5.0000e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9504 - loss: 0.1627 - precision: 0.9590 - recall: 0.9398 - val_accuracy: 0.9445 - val_loss: 0.1597 - val_precision: 0.9523 - val_recall: 0.9381 - learning_rate: 5.0000e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9468 - loss: 0.1620 - precision: 0.9562 - recall: 0.9385 - val_accuracy: 0.9472 - val_loss: 0.1623 - val_precision: 0.9524 - val_recall: 0.9386 - learning_rate: 5.0000e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9433 - loss: 0.1701 - precision: 0.9529 - recall: 0.9341 - val_accuracy: 0.9440 - val_loss: 0.1646 - val_precision: 0.9509 - val_recall: 0.9413 - learning_rate: 5.0000e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9471 - loss: 0.1613 - precision: 0.9561 - recall: 0.9372 - val_accuracy: 0.9514 - val_loss: 0.1601 - val_precision: 0.9569 - val_recall: 0.9466 - learning_rate: 5.0000e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9478 - loss: 0.1637 - precision: 0.9558 - recall: 0.9370 - val_accuracy: 0.9429 - val_loss: 0.1680 - val_precision: 0.9507 - val_recall: 0.9360 - learning_rate: 5.0000e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9496 - loss: 0.1594 - precision: 0.9569 - recall: 0.9391 - val_accuracy: 0.9509 - val_loss: 0.1594 - val_precision: 0.9552 - val_recall: 0.9440 - learning_rate: 5.0000e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9503 - loss: 0.1558 - precision: 0.9585 - recall: 0.9418 - val_accuracy: 0.9488 - val_loss: 0.1609 - val_precision: 0.9577 - val_recall: 0.9429 - learning_rate: 5.0000e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9504 - loss: 0.1506 - precision: 0.9603 - recall: 0.9399 - val_accuracy: 0.9456 - val_loss: 0.1604 - val_precision: 0.9529 - val_recall: 0.9397 - learning_rate: 5.0000e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9524 - loss: 0.1524 - precision: 0.9598 - recall: 0.9437 - val_accuracy: 0.9472 - val_loss: 0.1581 - val_precision: 0.9529 - val_recall: 0.9392 - learning_rate: 5.0000e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9524 - loss: 0.1494 - precision: 0.9606 - recall: 0.9447 - val_accuracy: 0.9482 - val_loss: 0.1633 - val_precision: 0.9528 - val_recall: 0.9381 - learning_rate: 5.0000e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9554 - loss: 0.1420 - precision: 0.9620 - recall: 0.9460 - val_accuracy: 0.9514 - val_loss: 0.1544 - val_precision: 0.9542 - val_recall: 0.9456 - learning_rate: 5.0000e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9538 - loss: 0.1444 - precision: 0.9621 - recall: 0.9486 - val_accuracy: 0.9530 - val_loss: 0.1503 - val_precision: 0.9579 - val_recall: 0.9477 - learning_rate: 5.0000e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9543 - loss: 0.1497 - precision: 0.9630 - recall: 0.9451 - val_accuracy: 0.9498 - val_loss: 0.1532 - val_precision: 0.9552 - val_recall: 0.9450 - learning_rate: 5.0000e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9564 - loss: 0.1415 - precision: 0.9624 - recall: 0.9491 - val_accuracy: 0.9456 - val_loss: 0.1467 - val_precision: 0.9526 - val_recall: 0.9434 - learning_rate: 5.0000e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9571 - loss: 0.1410 - precision: 0.9619 - recall: 0.9496 - val_accuracy: 0.9482 - val_loss: 0.1584 - val_precision: 0.9540 - val_recall: 0.9413 - learning_rate: 5.0000e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9604 - loss: 0.1374 - precision: 0.9654 - recall: 0.9530 - val_accuracy: 0.9466 - val_loss: 0.1587 - val_precision: 0.9509 - val_recall: 0.9397 - learning_rate: 5.0000e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9567 - loss: 0.1363 - precision: 0.9648 - recall: 0.9479 - val_accuracy: 0.9477 - val_loss: 0.1640 - val_precision: 0.9540 - val_recall: 0.9402 - learning_rate: 5.0000e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9558 - loss: 0.1322 - precision: 0.9640 - recall: 0.9497 - val_accuracy: 0.9562 - val_loss: 0.1469 - val_precision: 0.9622 - val_recall: 0.9504 - learning_rate: 5.0000e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9508 - loss: 0.1436 - precision: 0.9589 - recall: 0.9433\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9508 - loss: 0.1436 - precision: 0.9589 - recall: 0.9433 - val_accuracy: 0.9498 - val_loss: 0.1569 - val_precision: 0.9557 - val_recall: 0.9434 - learning_rate: 5.0000e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9540 - loss: 0.1380 - precision: 0.9620 - recall: 0.9459 - val_accuracy: 0.9578 - val_loss: 0.1410 - val_precision: 0.9618 - val_recall: 0.9530 - learning_rate: 2.5000e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9654 - loss: 0.1208 - precision: 0.9706 - recall: 0.9574 - val_accuracy: 0.9552 - val_loss: 0.1439 - val_precision: 0.9606 - val_recall: 0.9504 - learning_rate: 2.5000e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9656 - loss: 0.1202 - precision: 0.9701 - recall: 0.9587 - val_accuracy: 0.9520 - val_loss: 0.1476 - val_precision: 0.9585 - val_recall: 0.9482 - learning_rate: 2.5000e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9625 - loss: 0.1198 - precision: 0.9712 - recall: 0.9559 - val_accuracy: 0.9509 - val_loss: 0.1478 - val_precision: 0.9553 - val_recall: 0.9472 - learning_rate: 2.5000e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9696 - loss: 0.1108 - precision: 0.9737 - recall: 0.9628 - val_accuracy: 0.9557 - val_loss: 0.1433 - val_precision: 0.9591 - val_recall: 0.9504 - learning_rate: 2.5000e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9645 - loss: 0.1084 - precision: 0.9687 - recall: 0.9595 - val_accuracy: 0.9568 - val_loss: 0.1378 - val_precision: 0.9612 - val_recall: 0.9530 - learning_rate: 2.5000e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9659 - loss: 0.1099 - precision: 0.9722 - recall: 0.9615 - val_accuracy: 0.9573 - val_loss: 0.1378 - val_precision: 0.9633 - val_recall: 0.9530 - learning_rate: 2.5000e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9652 - loss: 0.1112 - precision: 0.9720 - recall: 0.9573 - val_accuracy: 0.9594 - val_loss: 0.1378 - val_precision: 0.9629 - val_recall: 0.9546 - learning_rate: 2.5000e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9651 - loss: 0.1069 - precision: 0.9717 - recall: 0.9603 - val_accuracy: 0.9568 - val_loss: 0.1437 - val_precision: 0.9618 - val_recall: 0.9530 - learning_rate: 2.5000e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9690 - loss: 0.1027 - precision: 0.9747 - recall: 0.9643 - val_accuracy: 0.9605 - val_loss: 0.1388 - val_precision: 0.9629 - val_recall: 0.9557 - learning_rate: 2.5000e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m117/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9626 - loss: 0.1143 - precision: 0.9670 - recall: 0.9574\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9626 - loss: 0.1142 - precision: 0.9671 - recall: 0.9575 - val_accuracy: 0.9594 - val_loss: 0.1406 - val_precision: 0.9628 - val_recall: 0.9530 - learning_rate: 2.5000e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9673 - loss: 0.1047 - precision: 0.9720 - recall: 0.9635 - val_accuracy: 0.9600 - val_loss: 0.1360 - val_precision: 0.9634 - val_recall: 0.9557 - learning_rate: 1.2500e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9766 - loss: 0.0871 - precision: 0.9795 - recall: 0.9719 - val_accuracy: 0.9605 - val_loss: 0.1340 - val_precision: 0.9650 - val_recall: 0.9568 - learning_rate: 1.2500e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9699 - loss: 0.0958 - precision: 0.9759 - recall: 0.9653 - val_accuracy: 0.9589 - val_loss: 0.1310 - val_precision: 0.9634 - val_recall: 0.9557 - learning_rate: 1.2500e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9710 - loss: 0.0966 - precision: 0.9746 - recall: 0.9663 - val_accuracy: 0.9605 - val_loss: 0.1310 - val_precision: 0.9639 - val_recall: 0.9557 - learning_rate: 1.2500e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9701 - loss: 0.0933 - precision: 0.9749 - recall: 0.9655 - val_accuracy: 0.9594 - val_loss: 0.1326 - val_precision: 0.9634 - val_recall: 0.9562 - learning_rate: 1.2500e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9733 - loss: 0.0933 - precision: 0.9782 - recall: 0.9698 - val_accuracy: 0.9610 - val_loss: 0.1309 - val_precision: 0.9634 - val_recall: 0.9557 - learning_rate: 1.2500e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9722 - loss: 0.0914 - precision: 0.9749 - recall: 0.9674 - val_accuracy: 0.9621 - val_loss: 0.1309 - val_precision: 0.9645 - val_recall: 0.9573 - learning_rate: 1.2500e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9732 - loss: 0.1018 - precision: 0.9772 - recall: 0.9677 - val_accuracy: 0.9621 - val_loss: 0.1305 - val_precision: 0.9640 - val_recall: 0.9578 - learning_rate: 1.2500e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9658 - loss: 0.1102 - precision: 0.9732 - recall: 0.9612 - val_accuracy: 0.9616 - val_loss: 0.1313 - val_precision: 0.9645 - val_recall: 0.9578 - learning_rate: 1.2500e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9703 - loss: 0.1023 - precision: 0.9754 - recall: 0.9653 - val_accuracy: 0.9621 - val_loss: 0.1312 - val_precision: 0.9641 - val_recall: 0.9589 - learning_rate: 1.2500e-05\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9588 - loss: 0.1206 - precision: 0.9616 - recall: 0.9552\n",
      "Test - Accuracy: 0.9621 | Precision: 0.9640 | Recall: 0.9578\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from gtda.homology import CubicalPersistence\n",
    "from gtda.diagrams import PersistenceImage, PersistenceLandscape\n",
    "\n",
    "X_img = np.load(\"/home/sajedhamdan/Desktop/skin_cancer/images_train_256x192.npy\")\n",
    "y = np.load(\"/home/sajedhamdan/Desktop/skin_cancer/train_labels.npy\")\n",
    "X_img = preprocess_input(X_img.astype(np.float32))\n",
    "y_cat = to_categorical(y)\n",
    "\n",
    "sample_size = 2000\n",
    "X_img, _, y, _ = train_test_split(X_img, y, train_size=sample_size, stratify=y, random_state=42)\n",
    "\n",
    "# TDA feature extraction\n",
    "def extract_tda_features(X_rgb):\n",
    "    X_gray = np.dot(X_rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "    cp = CubicalPersistence(n_jobs=-1)\n",
    "    diagrams = cp.fit_transform(X_gray)\n",
    "\n",
    "    pi = PersistenceImage(sigma=1.0, n_bins=20, weight_function=lambda x: x[1] ** 2)\n",
    "    pi_feat = pi.fit_transform(diagrams).reshape(len(diagrams), -1)\n",
    "\n",
    "    pl = PersistenceLandscape(n_layers=5, n_bins=50)\n",
    "    pl_feat = pl.fit_transform(diagrams).reshape(len(diagrams), -1)\n",
    "\n",
    "    return np.hstack((pi_feat, pl_feat))\n",
    "\n",
    "print(\"Extracting TDA features...\")\n",
    "X_tda_features = extract_tda_features(X_img)\n",
    "print(\"TDA features shape:\", X_tda_features.shape)\n",
    "\n",
    "# CNN feature extraction\n",
    "resnet_base = ResNet50(include_top=False, weights='imagenet', input_shape=(192, 256, 3))\n",
    "for layer in resnet_base.layers[:-50]:\n",
    "    layer.trainable = False\n",
    "for layer in resnet_base.layers[-50:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "cnn_output = GlobalAveragePooling2D()(resnet_base.output)\n",
    "cnn_model = Model(resnet_base.input, cnn_output)\n",
    "\n",
    "print(\"Extracting CNN features...\")\n",
    "X_img_features = cnn_model.predict(X_img, batch_size=32, verbose=1)\n",
    "print(\"CNN features shape:\", X_img_features.shape)\n",
    "\n",
    "# combining CNN and TDA features\n",
    "X_combined = np.hstack((X_img_features, X_tda_features))\n",
    "\n",
    "print(\"Balancing with SMOTE...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "y_subset = y[:X_img_features.shape[0]]\n",
    "X_balanced, y_bal = smote.fit_resample(X_combined, y_subset)\n",
    "\n",
    "X_img_bal = X_balanced[:, :X_img_features.shape[1]]\n",
    "X_tda_bal = X_balanced[:, X_img_features.shape[1]:]\n",
    "y_bal_cat = to_categorical(y_bal)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_tda_norm = scaler.fit_transform(X_tda_bal)\n",
    "\n",
    "X_final = np.concatenate([X_img_bal, X_tda_norm], axis=1)\n",
    "print(\"Final input shape:\", X_final.shape)\n",
    "\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_final, y_bal_cat, test_size=0.2, random_state=42, stratify=y_bal\n",
    ")\n",
    "\n",
    "input_layer = Input(shape=(X_final.shape[1],))\n",
    "x = Dense(512, activation='relu')(input_layer)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output_layer = Dense(7, activation='softmax')(x)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Callbacks\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stop, lr_scheduler],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "results = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test - Accuracy: {results[1]:.4f} | Precision: {results[2]:.4f} | Recall: {results[3]:.4f}\")\n",
    "\n",
    "model.save(\"tda_resnet_model_v1_lr.keras\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
